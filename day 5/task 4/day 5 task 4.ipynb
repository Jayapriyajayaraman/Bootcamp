{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca75e099-5a0f-4820-b07a-13916cb631d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: Index(['Match_id', 'Team', 'Over_num', 'Commentary', 'batsman', 'score'], dtype='object')\n",
      "\n",
      "TF-IDF from scratch:\n",
      "        for       and        it   picked      over        up    couple  \\\n",
      "0  0.046452  0.136059  0.065347  0.12351  0.049643  0.064053  0.134495   \n",
      "1  0.000000  0.043539  0.052277  0.00000  0.039715  0.051242  0.000000   \n",
      "2  0.000000  0.051832  0.031117  0.00000  0.000000  0.061003  0.000000   \n",
      "3  0.000000  0.031099  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
      "4  0.029969  0.035112  0.021080  0.00000  0.032028  0.041324  0.000000   \n",
      "\n",
      "    mandeep        on  boundary  ...  wrath  uhoh  latent  microsix  whodve  \\\n",
      "0  0.406116  0.047905  0.084598  ...    0.0   0.0     0.0       0.0     0.0   \n",
      "1  0.216595  0.000000  0.000000  ...    0.0   0.0     0.0       0.0     0.0   \n",
      "2  0.000000  0.000000  0.000000  ...    0.0   0.0     0.0       0.0     0.0   \n",
      "3  0.000000  0.000000  0.000000  ...    0.0   0.0     0.0       0.0     0.0   \n",
      "4  0.000000  0.000000  0.000000  ...    0.0   0.0     0.0       0.0     0.0   \n",
      "\n",
      "   outunorthodox  paddlepulls  expresspacer  hastily  runnign  \n",
      "0            0.0          0.0           0.0      0.0      0.0  \n",
      "1            0.0          0.0           0.0      0.0      0.0  \n",
      "2            0.0          0.0           0.0      0.0      0.0  \n",
      "3            0.0          0.0           0.0      0.0      0.0  \n",
      "4            0.0          0.0           0.0      0.0      0.0  \n",
      "\n",
      "[5 rows x 11758 columns]\n",
      "\n",
      "TF-IDF using scikit-learn:\n",
      "    00  00000   01   02   03   04   05   06   07   09  ...  zipping  zips  \\\n",
      "0  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
      "1  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
      "2  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
      "3  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
      "4  0.0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
      "\n",
      "   zone  zones  zoning  zoomed  zoomer  zooming  zooms  zoots  \n",
      "0   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "1   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "2   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "3   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "4   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 11727 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "file_path = 'IPL_Match_Highlights_Commentary.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"Columns in dataset:\", df.columns)\n",
    "if 'Commentary' not in df.columns:\n",
    "    raise KeyError(\"Column 'Commentary' not found in the dataset\")\n",
    "text_data = df['Commentary'].dropna().tolist()\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
    "    return text\n",
    "processed_texts = [preprocess(text) for text in text_data]\n",
    "def compute_tf(text):\n",
    "    words = text.split()\n",
    "    word_count = Counter(words)\n",
    "    total_words = len(words)\n",
    "    return {word: count / total_words for word, count in word_count.items()}\n",
    "document_count = len(processed_texts)\n",
    "df_counts = Counter()\n",
    "for text in processed_texts:\n",
    "    words = set(text.split())\n",
    "    df_counts.update(words)\n",
    "idf = {word: math.log(document_count / (df_counts[word] + 1)) + 1 for word in df_counts}\n",
    "corpus_tfidf = []\n",
    "for text in processed_texts:\n",
    "    tf = compute_tf(text)\n",
    "    tfidf = {word: tf[word] * idf[word] for word in tf}\n",
    "    corpus_tfidf.append(tfidf)\n",
    "words = list(idf.keys())\n",
    "tfidf_matrix = np.zeros((document_count, len(words)))\n",
    "word_to_index = {word: i for i, word in enumerate(words)}\n",
    "for i, tfidf in enumerate(corpus_tfidf):\n",
    "    for word, value in tfidf.items():\n",
    "        tfidf_matrix[i, word_to_index[word]] = value\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix, columns=words)\n",
    "print(\"\\nTF-IDF from scratch:\")\n",
    "print(tfidf_df.head())\n",
    "vectorizer = TfidfVectorizer()\n",
    "sklearn_tfidf_matrix = vectorizer.fit_transform(processed_texts).toarray()\n",
    "sklearn_tfidf_df = pd.DataFrame(sklearn_tfidf_matrix, columns=vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF using scikit-learn:\")\n",
    "print(sklearn_tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b68f59-1820-4f9e-982c-abf6f4ed2d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
